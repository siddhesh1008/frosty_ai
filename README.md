
<div align="center">
  <img src="https://github.com/user-attachments/assets/ab186003-82ca-49b8-a34e-f5e38cb5ab4a" 
       alt="Frosty Logo" 
       width="600" height="600">
</div>


# â„ï¸ FROSTY AI Assistant

A browser-based **real-time conversational AI assistant** powered by **Google Gemini 2.5**, built with **FastAPI**, **Vanilla JS**, and **Docker** â€” optimized for speed, modularity, and remote access on the BOSGAME P5.

---

## ğŸš€ Features

- âš¡ **Gemini 2.5 Streaming** â€“ Real-time, token-by-token responses using Googleâ€™s latest Gemini API.  
- ğŸ§© **Modular Architecture** â€“ Add voice, camera, or robotics integrations without touching the core.  
- ğŸ–¥ï¸ **Beautiful Web UI** â€“ Modern Frosty-themed design with scrolling chat interface and dynamic updates.  
- ğŸ³ **Dockerized** â€“ Runs fully isolated; auto-restarts on boot.  
- ğŸŒ **Tailscale Ready** â€“ Securely access Frosty from anywhere on your network.

---

## ğŸ§  Architecture Overview

```
frosty_ai/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI entry point
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ chat.py             # /api/chat streaming endpoint
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ gemini_client.py    # Gemini 2.5 real-time streaming logic
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ settings.py         # Loads API keys and config
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html              # Frosty chat UI
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ style.css           # Interface styling
â”‚   â”‚   â””â”€â”€ script.js           # Streaming chat logic
â”‚   â””â”€â”€ assets/
â”‚       â””â”€â”€ logo.png            # Frosty logo
â”‚
â”œâ”€â”€ .env                        # Gemini API keys (excluded from Git)
â”œâ”€â”€ Dockerfile                  # Docker image definition
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # This file
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/frosty_ai.git
cd frosty_ai
```

### 2ï¸âƒ£ Create an `.env` File
```
GOOGLE_API_KEY=your_google_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-pro
```

âš ï¸ *Keep this file private. Do not commit to GitHub.*

---

### 3ï¸âƒ£ Build & Run with Docker
```bash
sudo docker build -t frosty-ai .
sudo docker run -d \
  --name frosty \
  -p 8000:8000 \
  -v ~/frosty_ai:/app \
  --restart always \
  frosty-ai
```

Then open Frosty in your browser:
```
http://<your-local-ip>:8000
```

If using **Tailscale**:
```
http://<your-tailscale-ip>:8000
```

---

### 4ï¸âƒ£ Auto-Start Frosty on Boot
```bash
sudo nano /etc/systemd/system/frosty.service
```

Add:
```ini
[Unit]
Description=FROSTY AI Assistant
After=docker.service
Requires=docker.service

[Service]
Restart=always
ExecStart=/usr/bin/docker start -a frosty
ExecStop=/usr/bin/docker stop -t 2 frosty

[Install]
WantedBy=multi-user.target
```

Then:
```bash
sudo systemctl enable frosty
sudo systemctl start frosty
```

---

## ğŸ’¬ Usage

- Type messages into Frostyâ€™s chat box and press **Enter** or **Send**.  
- Frosty streams Geminiâ€™s response in real-time â€” just like ChatGPT.  
- Supports multi-line messages, smooth scroll, and typing indicator.  

ğŸ’¡ You can easily extend Frosty with:
- ğŸ™ï¸ Voice recognition  
- ğŸ”Š Text-to-speech  
- ğŸ§  Context memory  
- ğŸ¤– ROS integration for robotics projects  

---

## ğŸ§© Tech Stack

| Layer | Technology |
|-------|-------------|
| **Frontend** | HTML, CSS, Vanilla JS |
| **Backend** | FastAPI, Uvicorn |
| **AI Model** | Google Gemini 2.5 Pro |
| **Runtime** | Docker |
| **Platform** | BOSGAME P5 (Linux / Ubuntu) |

---

## ğŸ“¦ Dependencies

```
fastapi
uvicorn
google-generativeai
python-dotenv
```

To install manually:
```bash
pip install -r requirements.txt
```

---

## ğŸ§­ Example Interaction

```
User: Hey Frosty, how are you?
Frosty: Iâ€™m running at full power and ready to help, Sid! âš™ï¸
```

---

## ğŸŒ Future Plans

- ğŸ™ï¸ Add mic input (Speech-to-Text)
- ğŸ”Š Add TTS for Frostyâ€™s voice
- ğŸ§  Implement memory for ongoing context
- ğŸ¤– Link to your AI Rover / ROS system
- ğŸŒ Deploy via WebSocket or LiveKit for multi-device chat

---

## ğŸ‘¨â€ğŸ’» Author

**Siddhesh (Sid)**  
ğŸ“ Masterâ€™s in Engineering & Sustainable Management â€“ Industry 4.0, Automation, Robotics & 3D Manufacturing  
ğŸ“ Based in Berlin, Germany  

ğŸ”— [LinkedIn](https://linkedin.com/in/) | [GitHub](https://github.com/)

---

## ğŸ§Š License

This project is licensed under the **MIT License**.  
Feel free to use, modify, and expand Frosty â€” just credit the original creator.

---

âœ¨ *Frosty â€“ Built to think, talk, and assist. Anywhere. Anytime.*

# â„ï¸ FROSTY AI Assistant

A browser-based **real-time conversational AI assistant** powered by **Google Gemini 2.5**, built with **FastAPI**, **Vanilla JS**, and **Docker** â€” optimized for speed, modularity, and remote access on the BOSGAME P5.

---

## ğŸš€ Features

- âš¡ **Gemini 2.5 Streaming** â€“ Real-time, token-by-token responses using Googleâ€™s latest Gemini API.  
- ğŸ§© **Modular Architecture** â€“ Add voice, camera, or robotics integrations without touching the core.  
- ğŸ–¥ï¸ **Beautiful Web UI** â€“ Modern Frosty-themed design with scrolling chat interface and dynamic updates.  
- ğŸ³ **Dockerized** â€“ Runs fully isolated; auto-restarts on boot.  
- ğŸŒ **Tailscale Ready** â€“ Securely access Frosty from anywhere on your network.

---

## ğŸ§  Architecture Overview

```
frosty_ai/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI entry point
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ chat.py             # /api/chat streaming endpoint
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ gemini_client.py    # Gemini 2.5 real-time streaming logic
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ settings.py         # Loads API keys and config
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html              # Frosty chat UI
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ style.css           # Interface styling
â”‚   â”‚   â””â”€â”€ script.js           # Streaming chat logic
â”‚   â””â”€â”€ assets/
â”‚       â””â”€â”€ logo.png            # Frosty logo
â”‚
â”œâ”€â”€ .env                        # Gemini API keys (excluded from Git)
â”œâ”€â”€ Dockerfile                  # Docker image definition
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # This file
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/frosty_ai.git
cd frosty_ai
```

### 2ï¸âƒ£ Create an `.env` File
```
GOOGLE_API_KEY=your_google_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-pro
```

âš ï¸ *Keep this file private. Do not commit to GitHub.*

---

### 3ï¸âƒ£ Build & Run with Docker
```bash
sudo docker build -t frosty-ai .
sudo docker run -d \
  --name frosty \
  -p 8000:8000 \
  -v ~/frosty_ai:/app \
  --restart always \
  frosty-ai
```

Then open Frosty in your browser:
```
http://<your-local-ip>:8000
```

If using **Tailscale**:
```
http://<your-tailscale-ip>:8000
```

---

### 4ï¸âƒ£ Auto-Start Frosty on Boot
```bash
sudo nano /etc/systemd/system/frosty.service
```

Add:
```ini
[Unit]
Description=FROSTY AI Assistant
After=docker.service
Requires=docker.service

[Service]
Restart=always
ExecStart=/usr/bin/docker start -a frosty
ExecStop=/usr/bin/docker stop -t 2 frosty

[Install]
WantedBy=multi-user.target
```

Then:
```bash
sudo systemctl enable frosty
sudo systemctl start frosty
```

---

## ğŸ’¬ Usage

- Type messages into Frostyâ€™s chat box and press **Enter** or **Send**.  
- Frosty streams Geminiâ€™s response in real-time â€” just like ChatGPT.  
- Supports multi-line messages, smooth scroll, and typing indicator.  

ğŸ’¡ You can easily extend Frosty with:
- ğŸ™ï¸ Voice recognition  
- ğŸ”Š Text-to-speech  
- ğŸ§  Context memory  
- ğŸ¤– ROS integration for robotics projects  

---

## ğŸ§© Tech Stack

| Layer | Technology |
|-------|-------------|
| **Frontend** | HTML, CSS, Vanilla JS |
| **Backend** | FastAPI, Uvicorn |
| **AI Model** | Google Gemini 2.5 Pro |
| **Runtime** | Docker |
| **Platform** | BOSGAME P5 (Linux / Ubuntu) |

---

## ğŸ“¦ Dependencies

```
fastapi
uvicorn
google-generativeai
python-dotenv
```

To install manually:
```bash
pip install -r requirements.txt
```

---

## ğŸ§­ Example Interaction

```
User: Hey Frosty, how are you?
Frosty: Iâ€™m running at full power and ready to help, Sid! âš™ï¸
```

---

## ğŸŒ Future Plans

- ğŸ™ï¸ Add mic input (Speech-to-Text)
- ğŸ”Š Add TTS for Frostyâ€™s voice
- ğŸ§  Implement memory for ongoing context
- ğŸ¤– Link to your AI Rover / ROS system
- ğŸŒ Deploy via WebSocket or LiveKit for multi-device chat

---

## ğŸ‘¨â€ğŸ’» Author

**Siddhesh (Sid)**  
ğŸ“ Masterâ€™s in Engineering & Sustainable Management â€“ Industry 4.0, Automation, Robotics & 3D Manufacturing  
ğŸ“ Based in Berlin, Germany  

ğŸ”— [LinkedIn](https://linkedin.com/in/) | [GitHub](https://github.com/)

---

## ğŸ§Š License

This project is licensed under the **MIT License**.  
Feel free to use, modify, and expand Frosty â€” just credit the original creator.

---

âœ¨ *Frosty â€“ Built to think, talk, and assist. Anywhere. Anytime.*

# â„ï¸ FROSTY AI Assistant

A browser-based **real-time conversational AI assistant** powered by **Google Gemini 2.5**, built with **FastAPI**, **Vanilla JS**, and **Docker** â€” optimized for speed, modularity, and remote access on the BOSGAME P5.

---

## ğŸš€ Features

- âš¡ **Gemini 2.5 Streaming** â€“ Real-time, token-by-token responses using Googleâ€™s latest Gemini API.  
- ğŸ§© **Modular Architecture** â€“ Add voice, camera, or robotics integrations without touching the core.  
- ğŸ–¥ï¸ **Beautiful Web UI** â€“ Modern Frosty-themed design with scrolling chat interface and dynamic updates.  
- ğŸ³ **Dockerized** â€“ Runs fully isolated; auto-restarts on boot.  
- ğŸŒ **Tailscale Ready** â€“ Securely access Frosty from anywhere on your network.

---

## ğŸ§  Architecture Overview

```
frosty_ai/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI entry point
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ chat.py             # /api/chat streaming endpoint
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ gemini_client.py    # Gemini 2.5 real-time streaming logic
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ settings.py         # Loads API keys and config
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html              # Frosty chat UI
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ style.css           # Interface styling
â”‚   â”‚   â””â”€â”€ script.js           # Streaming chat logic
â”‚   â””â”€â”€ assets/
â”‚       â””â”€â”€ logo.png            # Frosty logo
â”‚
â”œâ”€â”€ .env                        # Gemini API keys (excluded from Git)
â”œâ”€â”€ Dockerfile                  # Docker image definition
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # This file
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/frosty_ai.git
cd frosty_ai
```

### 2ï¸âƒ£ Create an `.env` File
```
GOOGLE_API_KEY=your_google_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-pro
```

âš ï¸ *Keep this file private. Do not commit to GitHub.*

---

### 3ï¸âƒ£ Build & Run with Docker
```bash
sudo docker build -t frosty-ai .
sudo docker run -d \
  --name frosty \
  -p 8000:8000 \
  -v ~/frosty_ai:/app \
  --restart always \
  frosty-ai
```

Then open Frosty in your browser:
```
http://<your-local-ip>:8000
```

If using **Tailscale**:
```
http://<your-tailscale-ip>:8000
```

---

### 4ï¸âƒ£ Auto-Start Frosty on Boot
```bash
sudo nano /etc/systemd/system/frosty.service
```

Add:
```ini
[Unit]
Description=FROSTY AI Assistant
After=docker.service
Requires=docker.service

[Service]
Restart=always
ExecStart=/usr/bin/docker start -a frosty
ExecStop=/usr/bin/docker stop -t 2 frosty

[Install]
WantedBy=multi-user.target
```

Then:
```bash
sudo systemctl enable frosty
sudo systemctl start frosty
```

---

## ğŸ’¬ Usage

- Type messages into Frostyâ€™s chat box and press **Enter** or **Send**.  
- Frosty streams Geminiâ€™s response in real-time â€” just like ChatGPT.  
- Supports multi-line messages, smooth scroll, and typing indicator.  

ğŸ’¡ You can easily extend Frosty with:
- ğŸ™ï¸ Voice recognition  
- ğŸ”Š Text-to-speech  
- ğŸ§  Context memory  
- ğŸ¤– ROS integration for robotics projects  

---

## ğŸ§© Tech Stack

| Layer | Technology |
|-------|-------------|
| **Frontend** | HTML, CSS, Vanilla JS |
| **Backend** | FastAPI, Uvicorn |
| **AI Model** | Google Gemini 2.5 Pro |
| **Runtime** | Docker |
| **Platform** | BOSGAME P5 (Linux / Ubuntu) |

---

## ğŸ“¦ Dependencies

```
fastapi
uvicorn
google-generativeai
python-dotenv
```

To install manually:
```bash
pip install -r requirements.txt
```

---

## ğŸ§­ Example Interaction

```
User: Hey Frosty, how are you?
Frosty: Iâ€™m running at full power and ready to help, Sid! âš™ï¸
```

---

## ğŸŒ Future Plans

- ğŸ™ï¸ Add mic input (Speech-to-Text)
- ğŸ”Š Add TTS for Frostyâ€™s voice
- ğŸ§  Implement memory for ongoing context
- ğŸ¤– Link to your AI Rover / ROS system
- ğŸŒ Deploy via WebSocket or LiveKit for multi-device chat

---

## ğŸ‘¨â€ğŸ’» Author

**Siddhesh (Sid)**  
ğŸ“ Masterâ€™s in Engineering & Sustainable Management â€“ Industry 4.0, Automation, Robotics & 3D Manufacturing  
ğŸ“ Based in Berlin, Germany  

ğŸ”— [LinkedIn](https://linkedin.com/in/) | [GitHub](https://github.com/)

---

## ğŸ§Š License

This project is licensed under the **MIT License**.  
Feel free to use, modify, and expand Frosty â€” just credit the original creator.

---

âœ¨ *Frosty â€“ Built to think, talk, and assist. Anywhere. Anytime.*
